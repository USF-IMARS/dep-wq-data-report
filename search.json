[
  {
    "objectID": "seacar_compare.html",
    "href": "seacar_compare.html",
    "title": "Dep-wq-data-report",
    "section": "",
    "text": "Comparison of IMaRS QC and SEACAR QC outputs for DEP project\n\n\n\n\n(code) import libraries & functions\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  install.packages(\"librarian\")\n}\nlibrarian::shelf(\n  ggplot2,\n  glue,\n  here,\n  readxl,\n  tidyverse,\n  utils\n)\n\n\n\n\nCode\n# unzip SEACAR files\nlibrary(utils)\nlibrary(glue)\n\ninput_dir &lt;- here(\"./data/01-SEACAR_raw\")\noutput_dir &lt;- here(\"./data/02-SEACAR_unzipped\")\n\n# Create the output directory if it doesn't exist\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\n# List all .zip files in the input directory\nzip_files &lt;- list.files(\n  input_dir, pattern = \"\\\\.zip$\", full.names = TRUE\n)\n\n# Loop through each zip file\nfor (zip_file in zip_files) {\n  # Get the base name of the zip file \n  # (without directory and .zip extension)\n  zip_name &lt;- tools::file_path_sans_ext(basename(zip_file))\n  \n  cat(glue(\"unzipping to {output_dir}/{zip_name}/...\"))\n  \n  # Create a subfolder in the output directory \n  # with the name of the zip file\n  unzip_dir &lt;- file.path(output_dir, zip_name)\n  if (!dir.exists(unzip_dir)) {\n    dir.create(unzip_dir)\n  }\n  \n  # Unzip the file into the created subfolder\n  unzip(zip_file, exdir = unzip_dir)\n  cat(\"done.\\n\")\n}\n\n\nunzipping to /home/tylar/repos/dep-wq-data-report/./data/02-SEACAR_unzipped/AOML/...done.\n\n\n\n\nCode\n# Load SEACAR file\nseacar_data &lt;- read_delim(\n  here(\"./data/02-SEACAR_unzipped/AOML/Discrete\\ WQ\\ -\\ 3.txt\"),\n  delim=\"|\"\n)\n\n\nRows: 22456 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"|\"\nchr  (22): ProgramName, Habitat, IndicatorName, ParameterName, ParameterUnit...\ndbl  (12): RowID, ProgramID, IndicatorID, ParameterID, AreaID, ResultValue, ...\ndttm  (2): SampleDate, ExportVersion\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Load IMaRS-processed data & align to SEACAR columns\nimars_data &lt;- read_csv(\n  \"./data/df_cleaned.csv\"\n) %&gt;%\n  filter(Source == \"AOML\") %&gt;%\n  mutate(\n    ParameterName = Parameter,\n    OriginalLatitude = Latitude,\n    OriginalLongitude = Longitude,\n    ProgramLocationID = Site,\n    ResultValue = verbatimValue,\n    SampleDate = glue(\n      \"{Year}-{sprintf('%02d', Month)}-{sprintf('%02d', Day)}\"\n    )  \n  )\n\n\nRows: 331523 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Source, Site, Parameter, Units\ndbl (13): ...1, Latitude, Longitude, Month, Day, Year, Value, Sample Depth, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\nParameterName columns have different values for same data. Some columns appear to not exist in both.\n\n\nprint unique values for param name\nprint(\"=== IMaRS ==========================\")\n\n\n[1] \"=== IMaRS ==========================\"\n\n\nprint unique values for param name\nprint(unique(imars_data$ParameterName))\n\n\n[1] \"Chlorophyll a\"       \"Ammonium (N)\"        \"Nitrate-Nitrite (N)\"\n[4] \"Nitrite (N)\"         \"Nitrate (N)\"         \"Orthophosphate (P)\" \n[7] \"Silica\"             \n\n\nprint unique values for param name\nprint(\"=== SEACAR ==========================\")\n\n\n[1] \"=== SEACAR ==========================\"\n\n\nprint unique values for param name\nprint(unique(seacar_data$ParameterName))\n\n\n [1] \"Water Temperature\"                        \n [2] \"Light Extinction Coefficient\"             \n [3] \"NO2+3, Filtered\"                          \n [4] \"Colored Dissolved Organic Matter\"         \n [5] \"Chlorophyll a, Uncorrected for Pheophytin\"\n [6] \"Phosphate, Filtered (PO4)\"                \n [7] \"Total Suspended Solids\"                   \n [8] \"Ammonium, Filtered (NH4)\"                 \n [9] \"pH\"                                       \n[10] \"Salinity\"                                 \n\n\nA mapping of names manually creating using AOML data is below:\n\n\n\nIMaRS Name\nSEACAR name\n\n\n\n\nAmmonium (N)\nAmmonium, Filtered (NH4)\n\n\nChlorophyll a\nChlorophyll a, Uncorrected for Pheophytin\n\n\n-\nColored Dissolved Organic Matter\n\n\n-\nLight Extinction Coefficient\n\n\nNitrate (N)\n-\n\n\nNitrate-Nitrite (N)\nNO2+3, Filtered\n\n\nNitrite (N)\n-\n\n\nOrthophosphate (P)\n\n\n\n-\npH\n\n\n-\nPhosphate, Filtered (PO4)\n\n\n-\nSalinity\n\n\nSilica\n\n\n\n-\nTotal Suspended Solids\n\n\n-\nWater Temperature\n\n\n\n\n\nCode\n# Count the number of points for each reporting provider in SEACAR and DEP data\nseacar_count &lt;- seacar_data %&gt;%\n  group_by(ParameterName) %&gt;%\n  summarise(count = n())\n\nimars_count &lt;- imars_data %&gt;%\n  group_by(ParameterName) %&gt;%\n  summarise(count = n())\n\n# Combine and display the results\ncomparison_count &lt;- full_join(seacar_count, imars_count, by = \"ParameterName\", suffix = c(\"_SEACAR\", \"_IMaRS\"))\ncomparison_count\n\n\n# A tibble: 17 × 3\n   ParameterName                             count_SEACAR count_IMaRS\n   &lt;chr&gt;                                            &lt;int&gt;       &lt;int&gt;\n 1 Ammonium, Filtered (NH4)                          3283          NA\n 2 Chlorophyll a, Uncorrected for Pheophytin         4311          NA\n 3 Colored Dissolved Organic Matter                   572          NA\n 4 Light Extinction Coefficient                       400          NA\n 5 NO2+3, Filtered                                   3025          NA\n 6 Phosphate, Filtered (PO4)                         4519          NA\n 7 Salinity                                          4813          NA\n 8 Total Suspended Solids                             711          NA\n 9 Water Temperature                                  801          NA\n10 pH                                                  21          NA\n11 Ammonium (N)                                        NA        2311\n12 Chlorophyll a                                       NA        9280\n13 Nitrate (N)                                         NA        2303\n14 Nitrate-Nitrite (N)                                 NA        1536\n15 Nitrite (N)                                         NA        1968\n16 Orthophosphate (P)                                  NA        2649\n17 Silica                                              NA        6262\n\n\n\n\n\n\n\nCode\n# Select relevant nutrient columns from SEACAR and DEP datasets\n# Plot distributions side by side for SEACAR and IMaRS (DEP)\n\n# Combine the datasets with a new column to identify the source\ncombined_data &lt;- bind_rows(\n  seacar_data %&gt;% \n    select(ParameterName, ResultValue) %&gt;%\n    filter(ParameterName == \"Ammonium, Filtered (NH4)\") %&gt;% \n    mutate(Source = \"SEACAR\"),\n  imars_data %&gt;% \n    select(ParameterName, ResultValue) %&gt;%\n    filter(ParameterName == \"Ammonium (N)\") %&gt;% \n    mutate(Source = \"IMaRS\")\n)\n\n# Plot side-by-side distributions with log-scaled x-axis\nggplot(combined_data, aes(x = ResultValue, fill = Source)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Ammonium Distributions: SEACAR vs IMaRS (Log Scale)\",\n       x = \"Nutrient Value (Log Scale)\",\n       y = \"Density\",\n       fill = \"Source\") +\n  scale_x_log10() +   # Log scale on the x-axis\n  theme_minimal()\n\n\nWarning in scale_x_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 1663 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\n\n\nSite IDs in each are radically different:\n\n\nCode\nimars_sites &lt;- sort(unique(imars_data$ProgramLocationID))\nseacar_sites &lt;- sort(unique(seacar_data$ProgramLocationID))\n\nprint(\"=== IMaRS ==========================\")\n\n\n[1] \"=== IMaRS ==========================\"\n\n\nCode\nprint(imars_sites[1:5])\n\n\n[1] \"1\"  \"10\" \"11\" \"12\" \"13\"\n\n\nCode\nprint(\"=== SEACAR ==========================\")\n\n\n[1] \"=== SEACAR ==========================\"\n\n\nCode\nprint(seacar_sites[1:5])\n\n\n[1] \"1000B\" \"1001B\" \"1002B\" \"1003B\" \"1004B\"\n\n\nSEACAR data has many more site names\n\n\nCode\nprint(\"=== IMaRS ==========================\")\n\n\n[1] \"=== IMaRS ==========================\"\n\n\nCode\nprint(length(imars_sites))\n\n\n[1] 149\n\n\nCode\nprint(\"=== SEACAR ==========================\")\n\n\n[1] \"=== SEACAR ==========================\"\n\n\nCode\nprint(length(seacar_sites))\n\n\n[1] 4519\n\n\n\n\n\nCannot compare within stations until station number mapping is completed (see above section about station id malignment)."
  },
  {
    "objectID": "seacar_compare.html#data-loading-alignment",
    "href": "seacar_compare.html#data-loading-alignment",
    "title": "Dep-wq-data-report",
    "section": "",
    "text": "(code) import libraries & functions\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  install.packages(\"librarian\")\n}\nlibrarian::shelf(\n  ggplot2,\n  glue,\n  here,\n  readxl,\n  tidyverse,\n  utils\n)\n\n\n\n\nCode\n# unzip SEACAR files\nlibrary(utils)\nlibrary(glue)\n\ninput_dir &lt;- here(\"./data/01-SEACAR_raw\")\noutput_dir &lt;- here(\"./data/02-SEACAR_unzipped\")\n\n# Create the output directory if it doesn't exist\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\n# List all .zip files in the input directory\nzip_files &lt;- list.files(\n  input_dir, pattern = \"\\\\.zip$\", full.names = TRUE\n)\n\n# Loop through each zip file\nfor (zip_file in zip_files) {\n  # Get the base name of the zip file \n  # (without directory and .zip extension)\n  zip_name &lt;- tools::file_path_sans_ext(basename(zip_file))\n  \n  cat(glue(\"unzipping to {output_dir}/{zip_name}/...\"))\n  \n  # Create a subfolder in the output directory \n  # with the name of the zip file\n  unzip_dir &lt;- file.path(output_dir, zip_name)\n  if (!dir.exists(unzip_dir)) {\n    dir.create(unzip_dir)\n  }\n  \n  # Unzip the file into the created subfolder\n  unzip(zip_file, exdir = unzip_dir)\n  cat(\"done.\\n\")\n}\n\n\nunzipping to /home/tylar/repos/dep-wq-data-report/./data/02-SEACAR_unzipped/AOML/...done.\n\n\n\n\nCode\n# Load SEACAR file\nseacar_data &lt;- read_delim(\n  here(\"./data/02-SEACAR_unzipped/AOML/Discrete\\ WQ\\ -\\ 3.txt\"),\n  delim=\"|\"\n)\n\n\nRows: 22456 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"|\"\nchr  (22): ProgramName, Habitat, IndicatorName, ParameterName, ParameterUnit...\ndbl  (12): RowID, ProgramID, IndicatorID, ParameterID, AreaID, ResultValue, ...\ndttm  (2): SampleDate, ExportVersion\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Load IMaRS-processed data & align to SEACAR columns\nimars_data &lt;- read_csv(\n  \"./data/df_cleaned.csv\"\n) %&gt;%\n  filter(Source == \"AOML\") %&gt;%\n  mutate(\n    ParameterName = Parameter,\n    OriginalLatitude = Latitude,\n    OriginalLongitude = Longitude,\n    ProgramLocationID = Site,\n    ResultValue = verbatimValue,\n    SampleDate = glue(\n      \"{Year}-{sprintf('%02d', Month)}-{sprintf('%02d', Day)}\"\n    )  \n  )\n\n\nRows: 331523 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Source, Site, Parameter, Units\ndbl (13): ...1, Latitude, Longitude, Month, Day, Year, Value, Sample Depth, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "seacar_compare.html#inspect-an-example-provider-aoml",
    "href": "seacar_compare.html#inspect-an-example-provider-aoml",
    "title": "Dep-wq-data-report",
    "section": "",
    "text": "ParameterName columns have different values for same data. Some columns appear to not exist in both.\n\n\nprint unique values for param name\nprint(\"=== IMaRS ==========================\")\n\n\n[1] \"=== IMaRS ==========================\"\n\n\nprint unique values for param name\nprint(unique(imars_data$ParameterName))\n\n\n[1] \"Chlorophyll a\"       \"Ammonium (N)\"        \"Nitrate-Nitrite (N)\"\n[4] \"Nitrite (N)\"         \"Nitrate (N)\"         \"Orthophosphate (P)\" \n[7] \"Silica\"             \n\n\nprint unique values for param name\nprint(\"=== SEACAR ==========================\")\n\n\n[1] \"=== SEACAR ==========================\"\n\n\nprint unique values for param name\nprint(unique(seacar_data$ParameterName))\n\n\n [1] \"Water Temperature\"                        \n [2] \"Light Extinction Coefficient\"             \n [3] \"NO2+3, Filtered\"                          \n [4] \"Colored Dissolved Organic Matter\"         \n [5] \"Chlorophyll a, Uncorrected for Pheophytin\"\n [6] \"Phosphate, Filtered (PO4)\"                \n [7] \"Total Suspended Solids\"                   \n [8] \"Ammonium, Filtered (NH4)\"                 \n [9] \"pH\"                                       \n[10] \"Salinity\"                                 \n\n\nA mapping of names manually creating using AOML data is below:\n\n\n\nIMaRS Name\nSEACAR name\n\n\n\n\nAmmonium (N)\nAmmonium, Filtered (NH4)\n\n\nChlorophyll a\nChlorophyll a, Uncorrected for Pheophytin\n\n\n-\nColored Dissolved Organic Matter\n\n\n-\nLight Extinction Coefficient\n\n\nNitrate (N)\n-\n\n\nNitrate-Nitrite (N)\nNO2+3, Filtered\n\n\nNitrite (N)\n-\n\n\nOrthophosphate (P)\n\n\n\n-\npH\n\n\n-\nPhosphate, Filtered (PO4)\n\n\n-\nSalinity\n\n\nSilica\n\n\n\n-\nTotal Suspended Solids\n\n\n-\nWater Temperature\n\n\n\n\n\nCode\n# Count the number of points for each reporting provider in SEACAR and DEP data\nseacar_count &lt;- seacar_data %&gt;%\n  group_by(ParameterName) %&gt;%\n  summarise(count = n())\n\nimars_count &lt;- imars_data %&gt;%\n  group_by(ParameterName) %&gt;%\n  summarise(count = n())\n\n# Combine and display the results\ncomparison_count &lt;- full_join(seacar_count, imars_count, by = \"ParameterName\", suffix = c(\"_SEACAR\", \"_IMaRS\"))\ncomparison_count\n\n\n# A tibble: 17 × 3\n   ParameterName                             count_SEACAR count_IMaRS\n   &lt;chr&gt;                                            &lt;int&gt;       &lt;int&gt;\n 1 Ammonium, Filtered (NH4)                          3283          NA\n 2 Chlorophyll a, Uncorrected for Pheophytin         4311          NA\n 3 Colored Dissolved Organic Matter                   572          NA\n 4 Light Extinction Coefficient                       400          NA\n 5 NO2+3, Filtered                                   3025          NA\n 6 Phosphate, Filtered (PO4)                         4519          NA\n 7 Salinity                                          4813          NA\n 8 Total Suspended Solids                             711          NA\n 9 Water Temperature                                  801          NA\n10 pH                                                  21          NA\n11 Ammonium (N)                                        NA        2311\n12 Chlorophyll a                                       NA        9280\n13 Nitrate (N)                                         NA        2303\n14 Nitrate-Nitrite (N)                                 NA        1536\n15 Nitrite (N)                                         NA        1968\n16 Orthophosphate (P)                                  NA        2649\n17 Silica                                              NA        6262\n\n\n\n\n\n\n\nCode\n# Select relevant nutrient columns from SEACAR and DEP datasets\n# Plot distributions side by side for SEACAR and IMaRS (DEP)\n\n# Combine the datasets with a new column to identify the source\ncombined_data &lt;- bind_rows(\n  seacar_data %&gt;% \n    select(ParameterName, ResultValue) %&gt;%\n    filter(ParameterName == \"Ammonium, Filtered (NH4)\") %&gt;% \n    mutate(Source = \"SEACAR\"),\n  imars_data %&gt;% \n    select(ParameterName, ResultValue) %&gt;%\n    filter(ParameterName == \"Ammonium (N)\") %&gt;% \n    mutate(Source = \"IMaRS\")\n)\n\n# Plot side-by-side distributions with log-scaled x-axis\nggplot(combined_data, aes(x = ResultValue, fill = Source)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Ammonium Distributions: SEACAR vs IMaRS (Log Scale)\",\n       x = \"Nutrient Value (Log Scale)\",\n       y = \"Density\",\n       fill = \"Source\") +\n  scale_x_log10() +   # Log scale on the x-axis\n  theme_minimal()\n\n\nWarning in scale_x_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 1663 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\n\n\nSite IDs in each are radically different:\n\n\nCode\nimars_sites &lt;- sort(unique(imars_data$ProgramLocationID))\nseacar_sites &lt;- sort(unique(seacar_data$ProgramLocationID))\n\nprint(\"=== IMaRS ==========================\")\n\n\n[1] \"=== IMaRS ==========================\"\n\n\nCode\nprint(imars_sites[1:5])\n\n\n[1] \"1\"  \"10\" \"11\" \"12\" \"13\"\n\n\nCode\nprint(\"=== SEACAR ==========================\")\n\n\n[1] \"=== SEACAR ==========================\"\n\n\nCode\nprint(seacar_sites[1:5])\n\n\n[1] \"1000B\" \"1001B\" \"1002B\" \"1003B\" \"1004B\"\n\n\nSEACAR data has many more site names\n\n\nCode\nprint(\"=== IMaRS ==========================\")\n\n\n[1] \"=== IMaRS ==========================\"\n\n\nCode\nprint(length(imars_sites))\n\n\n[1] 149\n\n\nCode\nprint(\"=== SEACAR ==========================\")\n\n\n[1] \"=== SEACAR ==========================\"\n\n\nCode\nprint(length(seacar_sites))\n\n\n[1] 4519\n\n\n\n\n\nCannot compare within stations until station number mapping is completed (see above section about station id malignment)."
  },
  {
    "objectID": "parameters.html",
    "href": "parameters.html",
    "title": "Parameter Reports",
    "section": "",
    "text": "(code) import libraries & functions\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  quarto\n)\nsource(\"R/getData.R\")\ndata &lt;- getData()\n\n\n\nParameters\nUsing the clean data after completing Sites QC.\nAvailable parameters:\n\n\n(code) view unique parameters\n# print unique values in `Parameter` column\nunique_parameters &lt;- unique(data$Parameter)\nprint(unique_parameters)\n\n\n [1] \"Chlorophyll a\"            \"Ammonium (N)\"            \n [3] \"Nitrate-Nitrite (N)\"      \"Nitrite (N)\"             \n [5] \"Nitrate (N)\"              \"Orthophosphate (P)\"      \n [7] \"Silica\"                   \"Nitrogen- Total\"         \n [9] \"Nitrogen- Total Kjeldahl\" \"Phosphorus- Total\"       \n[11] \"Turbidity\"                \"Ammonia (N)\"             \n\n\n(code) view unique parameters\n# # create a violin plot of `Value` grouped by each `Parameter`\n# NOTE: this ran for 20min and never finished\n# ggplot2::ggplot(df, aes(x=Parameter, y=Value)) +\n#     geom_violin(trim=FALSE) +\n#     theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n#     labs(title=\"Violin Plot of Values by Parameter\",\n#          x=\"Parameter\",\n#          y=\"Value\")\n\n# TODO: print n observations per parameter\n\n\nEach parameter is filtered using the following min+max bounds.\n\n\nprint table of param bounds\n# NOTE: each row should *exactly* match the unique_parameters above\ncsvPath &lt;- \"parameter_bounds.csv\"\n\n# Read the CSV data\ndata &lt;- read.csv(csvPath, stringsAsFactors = FALSE)\n\n# Print the data frame\nprint(data)\n\n\n                       param min   max\n1  Ammonium (N)                0   6.0\n2  Nitrate (N)                 0  10.0\n3  Chlorophyll a               0  75.0\n4  Nitrate-Nitrite (N)         0   8.0\n5  Nitrite (N)                 0   0.5\n6  Nitrogen- Total             0   6.0\n7  Nitrogen- Total Kjeldahl    0   5.0\n8  Orthophosphate (P)          0  10.0\n9  Phosphorus- Total           0   2.0\n10 Silica                      0  20.0\n11 Turbidity                   0 200.0\n\n\nDetails on bound filtering and more info are in each parameter report listed below.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmmonia (N)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmmonium (N)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChlorophyll a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNitrate (N)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNitrate-Nitrite (N)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNitrite (N)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNitrogen- Total\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNitrogen- Total Kjeldahl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrthophosphate (P)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhosphorus- Total\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilica\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTurbidity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "sites_qc.html",
    "href": "sites_qc.html",
    "title": "Sites QC",
    "section": "",
    "text": "Code\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  dplyr,\n  glue,\n  ggplot2,\n  here,\n  skimr,\n)\n\nsource(here(\"R/getData.R\"))\n\n\n\n\nload data & skim\ndf &lt;- getRawData()\n\n\nNew names:\n• `` -&gt; `...1`\n\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `Value = as.numeric(Value)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nload data & skim\nprint(skimr::skim(df))\n\n\n── Data Summary ────────────────────────\n                           Values\nName                       df    \nNumber of rows             715257\nNumber of columns          16    \n_______________________          \nColumn type frequency:           \n  character                7     \n  numeric                  9     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable     n_missing complete_rate min max empty n_unique whitespace\n1 Source                   94         1.00    3  21     0       12          0\n2 Site                      0         1       1  28     0     2510          0\n3 Parameter                 0         1       6  24     0       12          0\n4 Units                   968         0.999   2   9     0       12          0\n5 verbatimValue        138417         0.806   0  11  2381    96304          0\n6 VerbatimLatitude      19208         0.973   2  11     0    15175          0\n7 verbatimLongitude     19248         0.973   3  12     0    10580          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate       mean         sd     p0        p25\n1 ...1                  0         1     357629     206477.       1   178815    \n2 Latitude          19208         0.973     25.4        0.827   23.7     24.7  \n3 Longitude         19248         0.973    -81.0        0.815  -85.7    -81.5  \n4 Month               114         1.00       6.56       3.42     1        4    \n5 Day                1614         0.998     14.1        8.23     1        7    \n6 Year                114         1.00    2012.         8.90  1995     2004    \n7 Value            322096         0.550      0.660      4.49   -80.5      0.008\n8 Sample Depth      22214         0.969      3.57      12.2      0        0.5  \n9 Total Depth      343781         0.519      9.01       9.49     0        3    \n          p50        p75     p100 hist \n1 357629      536443     715257   ▇▇▇▇▇\n2     25.2        25.9       30.8 ▇▇▂▁▁\n3    -80.9       -80.2      -79.8 ▁▁▁▆▇\n4      7          10         12   ▇▅▆▅▇\n5     13          20         31   ▇▇▆▅▃\n6   2015        2021       2024   ▃▃▃▃▇\n7      0.0990      0.382   1626   ▇▁▁▁▁\n8      0.5         3.5     2494   ▇▁▁▁▁\n9      6          11.2      121.  ▇▁▁▁▁\n\n\n\n\nfunction for plotting sites histogram\nsite_histogram &lt;- function(df){\n  number_of_unique_sites &lt;- df %&gt;% summarise(unique_sites = dplyr::n_distinct(Site))\n\n  site_counts &lt;- df %&gt;%\n    group_by(Site) %&gt;%\n    summarise(Count = n())\n  \n  ggplot(site_counts, aes(x = Count)) +\n    geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n    labs(title = glue(\"Histogram of Rows Per Site (total sites: {number_of_unique_sites})\"),\n         x = \"Number of Rows\",\n         y = \"Number of Sites\") +\n    theme_minimal()\n}\n\n\n\n\nshow initial sites setup\nsite_histogram(df)\n\n\n\n\n\n\n\n\n\n\n\ndrop rows without Year, Value, Lat, or Lon\ndf &lt;- df %&gt;%\n  filter(!is.na(Year) & !is.na(Value) & !is.na(Latitude) & !is.na(Longitude))\n\nsite_histogram(df)\n\n\n\n\n\n\n\n\n\n\n\nremove sites with &lt; 20 data points\ndf &lt;- df %&gt;%\n  group_by(Site) %&gt;%\n  filter(n() &gt;= 20) %&gt;%\n  ungroup()  # It's a good practice to ungroup data after operations like this\n\nsite_histogram(df)\n\n\n\n\n\n\n\n\n\n\n\nremove sites with no data since last two years (2022)\n# TODO: should calculate \"last two years\" from latest date in the data\nlatest_year &lt;- max(df$Year)\n\nggplot(df, aes(x = Year)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"N Rows per year\",\n       x = \"Year\",\n       y = \"N Rows\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nremove sites with no data since last two years (2022)\nsites_with_recent_data &lt;- df %&gt;%\n  filter(Year &gt; latest_year-2) %&gt;%  # Filter for rows with Year greater than 2022\n  distinct(Site)           # Get unique sites that meet the criteria\n\ndf &lt;- df %&gt;%\n  semi_join(sites_with_recent_data, by = \"Site\")  # Keep rows where 'Site' matches those in the recent data list\n\nsite_histogram(df)\n\n\n\n\n\n\n\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(df, \"data/df_cleaned_01.csv\", row.names = FALSE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dep-wq-data-report",
    "section": "",
    "text": "This collection of reports summarizes data provided by the Florida Department of Environmental Protection via SEACAR.\nThe recommended quality control cleaning steps are applied and explained.\nReports are generated\n\nfor each Water Quality (WQ) parameter\nshowing rows provided by each data provider\nrecommended quality control filtering across all sites\ndetails on the data files provided\n\nThe cleaned version of this data is fed into the FL DEP WQ Dashboard for site-by-site exploration.\nSource code for this website (and associated analysis) can be found at github/USF-IMaRS/dep-wq-data-report."
  },
  {
    "objectID": "parameter_reports/Nitrogen- Total Kjeldahl.html",
    "href": "parameter_reports/Nitrogen- Total Kjeldahl.html",
    "title": "Nitrogen- Total Kjeldahl",
    "section": "",
    "text": "Nitrogen- Total Kjeldahl Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 5\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 5\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             35116      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  21     0        9          0\n2 Site                  0             1   1  28     0      504          0\n3 Parameter             0             1  24  24     0        1          0\n4 Units                 0             1   4   4     0        1          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate       mean        sd       p0\n 1 ...1                      0         1     486850.    63252.    442538  \n 2 Latitude                  0         1         25.7       0.811     24.5\n 3 Longitude                 0         1        -80.5       0.659    -85.7\n 4 Month                     0         1          6.66      3.40       1  \n 5 Day                       0         1         12.7       7.82       1  \n 6 Year                      0         1       2017.        7.45    1995  \n 7 Value                     0         1          0.235     0.292      0  \n 8 Sample.Depth            888         0.975      3.37     21.1        0  \n 9 Total.Depth           24186         0.311      7.47      6.93       0  \n10 verbatimValue             0         1          0.235     0.292      0  \n11 VerbatimLatitude          0         1         25.7       0.811     24.5\n12 verbatimLongitude         0         1        -80.5       0.659    -85.7\n13 Value_orig                0         1          0.235     0.292      0  \n          p25        p50       p75     p100 hist \n 1 451331.    460110.    481313.   639713   ▇▁▁▁▂\n 2     25.0       25.8       26.3      30.8 ▆▇▁▁▁\n 3    -80.5      -80.2      -80.1     -80.0 ▁▁▁▁▇\n 4      4          7         10        12   ▇▅▆▆▇\n 5      6         12         18        31   ▇▇▅▃▂\n 6   2016       2020       2022      2024   ▁▁▁▂▇\n 7      0.043      0.139      0.28      4.4 ▇▁▁▁▁\n 8      0.5        0.5        2.9    2494   ▇▁▁▁▁\n 9      3          5.25       9.72    104.  ▇▁▁▁▁\n10      0.043      0.139      0.28      4.4 ▇▁▁▁▁\n11     25.0       25.8       26.3      30.8 ▆▇▁▁▁\n12    -80.5      -80.2      -80.1     -80.0 ▁▁▁▁▇\n13      0.043      0.139      0.28      4.4 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Silica.html",
    "href": "parameter_reports/Silica.html",
    "title": "Silica",
    "section": "",
    "text": "Silica Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 20\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 20\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             22144      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        5          0\n2 Site                  0             1   1  28     0      488          0\n3 Parameter             0             1   6   6     0        1          0\n4 Units                 0             1   4   9     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate       mean        sd         p0\n 1 ...1                      0         1     393422.    89251.    345229    \n 2 Latitude                  0         1         26.0       0.805     24.2  \n 3 Longitude                 0         1        -80.6       0.762    -83.6  \n 4 Month                     0         1          6.68      3.43       1    \n 5 Day                      28         0.999     12.5       7.58       1    \n 6 Year                      0         1       2017.        6.50    1995    \n 7 Value                     0         1          0.787     2.32       0    \n 8 Sample.Depth             29         0.999      3.25      7.66       0    \n 9 Total.Depth           19296         0.129      4.92      6.05       0.444\n10 verbatimValue             0         1          0.787     2.32       0    \n11 VerbatimLatitude          0         1         26.0       0.805     24.2  \n12 verbatimLongitude         0         1        -80.6       0.762    -83.6  \n13 Value_orig                0         1          0.787     2.32       0    \n          p25        p50        p75     p100 hist \n 1 355967.    361502.    367038.    634510   ▇▁▁▁▁\n 2     25.4       26.0       26.6       28.4 ▃▅▇▅▁\n 3    -81.2      -80.1      -80.1      -80.0 ▁▁▁▃▇\n 4      4          7         10         12   ▇▅▅▆▇\n 5      6         12         18         31   ▇▇▆▃▂\n 6   2017       2020       2021.      2023   ▁▁▁▁▇\n 7      0.016      0.047      0.295     19.9 ▇▁▁▁▁\n 8      0          0.5        2.54     247   ▇▁▁▁▁\n 9      1.91       3.01       6         52.7 ▇▁▁▁▁\n10      0.016      0.047      0.295     19.9 ▇▁▁▁▁\n11     25.4       26.0       26.6       28.4 ▃▅▇▅▁\n12    -81.2      -80.1      -80.1      -80.0 ▁▁▁▃▇\n13      0.016      0.047      0.295     19.9 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Nitrate (N).html",
    "href": "parameter_reports/Nitrate (N).html",
    "title": "Nitrate (N)",
    "section": "",
    "text": "Nitrate (N) Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 10\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 10\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             3636       \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        5          0\n2 Site                  0             1   1  28     0      285          0\n3 Parameter             0             1  11  11     0        1          0\n4 Units                 0             1   4   6     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate        mean         sd       p0\n 1 ...1                      0         1     438858.     184512.    270777  \n 2 Latitude                  0         1         25.7         0.971     24.4\n 3 Longitude                 0         1        -81.3         0.962    -83.6\n 4 Month                     0         1          6.95        3.45       1  \n 5 Day                      28         0.992     14.2         7.71       1  \n 6 Year                      0         1       2019.          4.12    2005  \n 7 Value                     0         1          0.0566      0.290      0  \n 8 Sample.Depth             28         0.992      2.62        7.76       0  \n 9 Total.Depth            2332         0.359      5.18        7.79       0.5\n10 verbatimValue             0         1          0.0566      0.290      0  \n11 VerbatimLatitude          0         1         25.7         0.971     24.4\n12 verbatimLongitude         0         1        -81.3         0.962    -83.6\n13 Value_orig                0         1          0.0566      0.290      0  \n          p25      p50         p75      p100 hist \n 1 276099.    278282.  648180.     649436    ▇▁▁▁▆\n 2     24.9       25.6     26.4        28.0  ▇▇▂▃▂\n 3    -81.9      -81.2    -80.3       -80.1  ▂▂▅▆▇\n 4      4          7       10          12    ▆▅▃▆▇\n 5      8         14       20          31    ▇▇▇▆▂\n 6   2017       2021     2023        2023    ▁▁▁▅▇\n 7      0          0        0.0104      8.11 ▇▁▁▁▁\n 8      0          0        0.5       120.   ▇▁▁▁▁\n 9      0.704      3        6.4        52.7  ▇▁▁▁▁\n10      0          0        0.0104      8.11 ▇▁▁▁▁\n11     24.9       25.6     26.4        28.0  ▇▇▂▃▂\n12    -81.9      -81.2    -80.3       -80.1  ▂▂▅▆▇\n13      0          0        0.0104      8.11 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Ammonia (N).html",
    "href": "parameter_reports/Ammonia (N).html",
    "title": "Ammonia (N)",
    "section": "",
    "text": "Ammonia (N) Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\nno rows removed\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             10130      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  11     0        7          0\n2 Site                  0             1   1   8     0      776          0\n3 Parameter             0             1  11  11     0        1          0\n4 Units                 0             1   4   4     0        1          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate        mean        sd           p0\n 1 ...1                      0         1     689230.     3110.     683929      \n 2 Latitude                  0         1         26.6       0.744      24.9    \n 3 Longitude                 0         1        -80.5       0.535     -85.2    \n 4 Month                     0         1          6.75      3.38        1      \n 5 Day                       0         1         13.7       8.01        1      \n 6 Year                      0         1       2023.        0.0358   2023      \n 7 Value                     0         1          0.0679    0.169       0.00165\n 8 Sample.Depth            149         0.985      1.42     14.9         0.014  \n 9 Total.Depth           10130         0        NaN        NA          NA      \n10 verbatimValue             0         1          0.0679    0.169       0.00165\n11 VerbatimLatitude          0         1         26.6       0.744      24.9    \n12 verbatimLongitude         0         1        -80.5       0.535     -85.2    \n13 Value_orig                0         1          0.0679    0.169       0.00165\n            p25       p50        p75      p100 hist   \n 1 686478.      689388.   691951.    694525    \"▇▇▆▇▇\"\n 2     25.9         26.7      27.2       30.8  \"▅▇▂▁▁\"\n 3    -80.9        -80.3     -80.1      -80.0  \"▁▁▁▂▇\"\n 4      4            7        10         12    \"▇▅▆▆▇\"\n 5      7           13        19         31    \"▇▇▆▅▃\"\n 6   2023         2023      2023       2024    \"▇▁▁▁▁\"\n 7      0.00918      0.02      0.061      6.77 \"▇▁▁▁▁\"\n 8      0.5          0.5       0.5     1463    \"▇▁▁▁▁\"\n 9     NA           NA        NA         NA    \" \"    \n10      0.00918      0.02      0.061      6.77 \"▇▁▁▁▁\"\n11     25.9         26.7      27.2       30.8  \"▅▇▂▁▁\"\n12    -80.9        -80.3     -80.1      -80.0  \"▁▁▁▂▇\"\n13      0.00918      0.02      0.061      6.77 \"▇▁▁▁▁\"\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Phosphorus- Total.html",
    "href": "parameter_reports/Phosphorus- Total.html",
    "title": "Phosphorus- Total",
    "section": "",
    "text": "Phosphorus- Total Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 2\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 2\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             50322      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  21     0        9          0\n2 Site                  0             1   1  28     0      986          0\n3 Parameter             0             1  17  17     0        1          0\n4 Units                 0             1   4   6     0        3          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate        mean         sd       p0\n 1 ...1                      0         1     565170.     63974.     505005  \n 2 Latitude                  0         1         25.9        0.850      24.5\n 3 Longitude                 0         1        -80.5        0.618     -85.7\n 4 Month                     0         1          6.68       3.41        1  \n 5 Day                       0         1         13.5        8.19        1  \n 6 Year                      0         1       2018.         6.62     1995  \n 7 Value                     0         1          0.0357     0.0842      0  \n 8 Sample.Depth           2845         0.943      1.97      17.8         0  \n 9 Total.Depth           37414         0.257      7.19       7.61        0  \n10 verbatimValue             0         1          0.0357     0.0842      0  \n11 VerbatimLatitude          0         1         25.9        0.850      24.5\n12 verbatimLongitude         0         1        -80.5        0.618     -85.7\n13 Value_orig                0         1          0.0357     0.0842      0  \n          p25        p50        p75      p100 hist \n 1 517649.    530820.    659085.    672577    ▇▁▁▁▃\n 2     25.4       25.9       26.4       30.8  ▅▇▂▁▁\n 3    -80.8      -80.2      -80.1      -80.0  ▁▁▁▂▇\n 4      4          7         10         12    ▇▅▅▆▇\n 5      7         12         20         31    ▇▇▆▃▃\n 6   2017       2020       2023       2024    ▁▁▁▂▇\n 7      0.006      0.014      0.026      1.97 ▇▁▁▁▁\n 8      0.5        0.5        0.5     2494    ▇▁▁▁▁\n 9      2.55       4.83       9.26     121.   ▇▁▁▁▁\n10      0.006      0.014      0.026      1.97 ▇▁▁▁▁\n11     25.4       25.9       26.4       30.8  ▅▇▂▁▁\n12    -80.8      -80.2      -80.1      -80.0  ▁▁▁▂▇\n13      0.006      0.014      0.026      1.97 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Nitrite (N).html",
    "href": "parameter_reports/Nitrite (N).html",
    "title": "Nitrite (N)",
    "section": "",
    "text": "Nitrite (N) Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 0.5\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 0.5\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             19515      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        5          0\n2 Site                  0             1   1  28     0      575          0\n3 Parameter             0             1  11  11     0        1          0\n4 Units                 0             1   4   6     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate         mean          sd       p0\n 1 ...1                      0        1      355482.      194320.     211877  \n 2 Latitude                  0        1          26.3          0.667      24.4\n 3 Longitude                 0        1         -80.4          0.661     -83.6\n 4 Month                     0        1           6.57         3.46        1  \n 5 Day                      21        0.999      12.3          7.42        1  \n 6 Year                      0        1        2021.           2.35     2005  \n 7 Value                     0        1           0.00449      0.0165      0  \n 8 Sample.Depth             21        0.999       3.95         8.00        0  \n 9 Total.Depth           18336        0.0604      5.84         8.14        0.5\n10 verbatimValue             0        1           0.00449      0.0165      0  \n11 VerbatimLatitude          0        1          26.3          0.667      24.4\n12 verbatimLongitude         0        1         -80.4          0.661     -83.6\n13 Value_orig                0        1           0.00449      0.0165      0  \n            p25        p50        p75     p100 hist \n 1 222842.      227721     642000.    647323   ▇▁▁▁▃\n 2     25.9         26.3       26.8       28.4 ▁▅▇▅▁\n 3    -80.1        -80.1      -80.1      -80.0 ▁▁▁▁▇\n 4      4            7         10         12   ▇▅▆▆▇\n 5      6           12         18         31   ▇▇▆▃▂\n 6   2019         2021       2023       2023   ▁▁▁▃▇\n 7      0.00102      0.002      0.004      0.5 ▇▁▁▁▁\n 8      0.5          0.5        4.4      247   ▇▁▁▁▁\n 9      0.719        4          7         52.7 ▇▁▁▁▁\n10      0.00102      0.002      0.004      0.5 ▇▁▁▁▁\n11     25.9         26.3       26.8       28.4 ▁▅▇▅▁\n12    -80.1        -80.1      -80.1      -80.0 ▁▁▁▁▇\n13      0.00102      0.002      0.004      0.5 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_report_template.html",
    "href": "parameter_report_template.html",
    "title": "Silica",
    "section": "",
    "text": "Silica Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 20\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 20\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             22144      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        5          0\n2 Site                  0             1   1  28     0      488          0\n3 Parameter             0             1   6   6     0        1          0\n4 Units                 0             1   4   9     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate       mean        sd         p0\n 1 ...1                      0         1     393422.    89251.    345229    \n 2 Latitude                  0         1         26.0       0.805     24.2  \n 3 Longitude                 0         1        -80.6       0.762    -83.6  \n 4 Month                     0         1          6.68      3.43       1    \n 5 Day                      28         0.999     12.5       7.58       1    \n 6 Year                      0         1       2017.        6.50    1995    \n 7 Value                     0         1          0.787     2.32       0    \n 8 Sample.Depth             29         0.999      3.25      7.66       0    \n 9 Total.Depth           19296         0.129      4.92      6.05       0.444\n10 verbatimValue             0         1          0.787     2.32       0    \n11 VerbatimLatitude          0         1         26.0       0.805     24.2  \n12 verbatimLongitude         0         1        -80.6       0.762    -83.6  \n13 Value_orig                0         1          0.787     2.32       0    \n          p25        p50        p75     p100 hist \n 1 355967.    361502.    367038.    634510   ▇▁▁▁▁\n 2     25.4       26.0       26.6       28.4 ▃▅▇▅▁\n 3    -81.2      -80.1      -80.1      -80.0 ▁▁▁▃▇\n 4      4          7         10         12   ▇▅▅▆▇\n 5      6         12         18         31   ▇▇▆▃▂\n 6   2017       2020       2021.      2023   ▁▁▁▁▇\n 7      0.016      0.047      0.295     19.9 ▇▁▁▁▁\n 8      0          0.5        2.54     247   ▇▁▁▁▁\n 9      1.91       3.01       6         52.7 ▇▁▁▁▁\n10      0.016      0.047      0.295     19.9 ▇▁▁▁▁\n11     25.4       26.0       26.6       28.4 ▃▅▇▅▁\n12    -81.2      -80.1      -80.1      -80.0 ▁▁▁▃▇\n13      0.016      0.047      0.295     19.9 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Chlorophyll a.html",
    "href": "parameter_reports/Chlorophyll a.html",
    "title": "Chlorophyll a",
    "section": "",
    "text": "Chlorophyll a Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 75\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 75\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             36813      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        9          0\n2 Site                  0             1   1  28     0      515          0\n3 Parameter             0             1  13  13     0        1          0\n4 Units                 0             1   4   4     0        1          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate      mean         sd     p0\n 1 ...1                      0         1     101919.   224634.       1  \n 2 Latitude                  0         1         25.6       0.835   24.3\n 3 Longitude                 0         1        -80.8       0.807  -85.7\n 4 Month                     0         1          6.73      3.45     1  \n 5 Day                      36         0.999     13.5       8.32     1  \n 6 Year                      0         1       2015.        8.15  1995  \n 7 Value                     0         1          1.42      3.13     0  \n 8 Sample.Depth             36         0.999      1.38     18.3      0  \n 9 Total.Depth           25218         0.315      7.19      7.52     0  \n10 verbatimValue             0         1          1.42      3.13     0  \n11 VerbatimLatitude          0         1         25.6       0.835   24.3\n12 verbatimLongitude         0         1        -80.8       0.807  -85.7\n13 Value_orig                0         1          1.42      3.13     0  \n         p25       p50      p75     p100 hist \n 1 11199     20429     31249    714809   ▇▁▁▁▁\n 2    24.8      25.5      26.1      30.8 ▇▆▁▁▁\n 3   -81.4     -80.4     -80.1     -80.0 ▁▁▁▃▇\n 4     4         7        10        12   ▇▅▅▅▇\n 5     7        12        20        31   ▇▇▆▃▃\n 6  2009      2018      2021      2023   ▁▂▂▂▇\n 7     0.276     0.495     1.28     70.9 ▇▁▁▁▁\n 8     0         0.5       0.5    2494   ▇▁▁▁▁\n 9     2.57      4.72      9.5     121.  ▇▁▁▁▁\n10     0.276     0.495     1.28     70.9 ▇▁▁▁▁\n11    24.8      25.5      26.1      30.8 ▇▆▁▁▁\n12   -81.4     -80.4     -80.1     -80.0 ▁▁▁▃▇\n13     0.276     0.495     1.28     70.9 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Ammonium (N).html",
    "href": "parameter_reports/Ammonium (N).html",
    "title": "Ammonium (N)",
    "section": "",
    "text": "Ammonium (N) Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 6\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 6\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             23550      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  21     0        9          0\n2 Site                  0             1   1  28     0      515          0\n3 Parameter             0             1  12  12     0        1          0\n4 Units                 0             1   4   6     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate        mean         sd      p0\n 1 ...1                      0        1      131266.     160487.    66448  \n 2 Latitude                  0        1          26.1         0.605    24.2\n 3 Longitude                 0        1         -80.3         0.561   -83.6\n 4 Month                     0        1           6.65        3.42      1  \n 5 Day                      30        0.999      11.5         7.28      1  \n 6 Year                      0        1        2020.          3.10   1998  \n 7 Value                     0        1           0.0845      0.243     0  \n 8 Sample.Depth            552        0.977       3.49       23.9       0  \n 9 Total.Depth           22248        0.0553      5.37        7.93      0.5\n10 verbatimValue             0        1           0.0845      0.243     0  \n11 VerbatimLatitude          0        1          26.1         0.605    24.2\n12 verbatimLongitude         0        1         -80.3         0.561   -83.6\n13 Value_orig                0        1           0.0845      0.243     0  \n         p25       p50       p75     p100 hist \n 1 78823.    84712.    90599.    696626   ▇▁▁▁▁\n 2    25.8      26.0      26.4       28.0 ▁▂▇▃▁\n 3   -80.3     -80.1     -80.1      -80.0 ▁▁▁▁▇\n 4     4         7        10         12   ▇▅▅▆▇\n 5     6        10        16         31   ▇▆▅▂▁\n 6  2019      2020      2021       2023   ▁▁▁▂▇\n 7     0.006     0.014     0.065      5.5 ▇▁▁▁▁\n 8     0.5       0.5       2.5     2494   ▇▁▁▁▁\n 9     0.708     3.4       6.7       62.2 ▇▁▁▁▁\n10     0.006     0.014     0.065      5.5 ▇▁▁▁▁\n11    25.8      26.0      26.4       28.0 ▁▂▇▃▁\n12   -80.3     -80.1     -80.1      -80.0 ▁▁▁▁▇\n13     0.006     0.014     0.065      5.5 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Turbidity.html",
    "href": "parameter_reports/Turbidity.html",
    "title": "Turbidity",
    "section": "",
    "text": "Turbidity Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 200\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 200\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             41076      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0         1       3  21     0        8          0\n2 Site                  0         1       1  28     0      438          0\n3 Parameter             0         1       9   9     0        1          0\n4 Units                27         0.999   3   3     0        1          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate      mean        sd       p0\n 1 ...1                      0         1     591053.   17289.    566786  \n 2 Latitude                  0         1         25.6      0.748     24.5\n 3 Longitude                 0         1        -80.6      0.644    -82.6\n 4 Month                     0         1          6.58     3.43       1  \n 5 Day                       0         1         13.5      8.19       1  \n 6 Year                      0         1       2015.       7.43    1995  \n 7 Value                     0         1          1.22     2.53       0  \n 8 Sample.Depth           2585         0.937      3.28     6.58       0  \n 9 Total.Depth           23612         0.425      8.23     7.85       0  \n10 verbatimValue             0         1          1.22     2.53       0  \n11 VerbatimLatitude          0         1         25.6      0.748     24.5\n12 verbatimLongitude         0         1        -80.6      0.644    -82.6\n13 Value_orig                0         1          1.22     2.53       0  \n         p25      p50      p75     p100 hist \n 1 577188.   587522.  604183.  631243   ▇▇▅▃▂\n 2     24.8      25.7     26.1     27.2 ▇▃▇▅▂\n 3    -80.9     -80.2    -80.1    -80.0 ▁▁▁▁▇\n 4      3         7       10       12   ▇▅▅▆▇\n 5      7        12       19       31   ▇▇▆▃▃\n 6   2011      2018     2021     2023   ▁▁▂▂▇\n 7      0.25      0.6      1.3    177   ▇▁▁▁▁\n 8      0.5       0.5      3.2    121.  ▇▁▁▁▁\n 9      3.15      6       10.4    121.  ▇▁▁▁▁\n10      0.25      0.6      1.3    177   ▇▁▁▁▁\n11     24.8      25.7     26.1     27.2 ▇▃▇▅▂\n12    -80.9     -80.2    -80.1    -80.0 ▁▁▁▁▇\n13      0.25      0.6      1.3    177   ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Orthophosphate (P).html",
    "href": "parameter_reports/Orthophosphate (P).html",
    "title": "Orthophosphate (P)",
    "section": "",
    "text": "Orthophosphate (P) Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 10\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 10\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             31785      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        7          0\n2 Site                  0             1   1   8     0      863          0\n3 Parameter             0             1  18  18     0        1          0\n4 Units                 0             1   4   6     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate        mean          sd       p0\n 1 ...1                      0        1      453631.     164471.     314515  \n 2 Latitude                  0        1          26.3         0.697      24.4\n 3 Longitude                 0        1         -80.4         0.564     -85.2\n 4 Month                     0        1           6.65        3.43        1  \n 5 Day                      15        1.00       12.1         7.54        1  \n 6 Year                      0        1        2020.          3.52     1998  \n 7 Value                     0        1           0.0210      0.0754      0  \n 8 Sample.Depth             15        1.00        2.62        6.50        0  \n 9 Total.Depth           31098        0.0216      9.11        9.05        0.9\n10 verbatimValue             0        1           0.0210      0.0754      0  \n11 VerbatimLatitude          0        1          26.3         0.697      24.4\n12 verbatimLongitude         0        1         -80.4         0.564     -85.2\n13 Value_orig                0        1           0.0210      0.0754      0  \n          p25        p50       p75      p100 hist \n 1 331285     339231     675840    683928    ▇▁▁▁▅\n 2     25.8       26.2       26.8      30.8  ▂▇▂▁▁\n 3    -80.4      -80.1      -80.1     -80.0  ▁▁▁▁▇\n 4      4          7         10        12    ▇▅▅▆▇\n 5      6         11         17        31    ▇▆▅▃▂\n 6   2019       2021       2023      2023    ▁▁▁▂▇\n 7      0.002      0.004      0.01      2.09 ▇▁▁▁▁\n 8      0.5        0.5        0.5     247    ▇▁▁▁▁\n 9      4.9        6.4        8.35     52.7  ▇▁▁▁▁\n10      0.002      0.004      0.01      2.09 ▇▁▁▁▁\n11     25.8       26.2       26.8      30.8  ▂▇▂▁▁\n12    -80.4      -80.1      -80.1     -80.0  ▁▁▁▁▇\n13      0.002      0.004      0.01      2.09 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Nitrate-Nitrite (N).html",
    "href": "parameter_reports/Nitrate-Nitrite (N).html",
    "title": "Nitrate-Nitrite (N)",
    "section": "",
    "text": "Nitrate-Nitrite (N) Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 8\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 8\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             34293      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  21     0       11          0\n2 Site                  0             1   1  28     0     1038          0\n3 Parameter             0             1  19  19     0        1          0\n4 Units                 0             1   2   4     0        3          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate       mean         sd       p0\n 1 ...1                      0        1      358547.    262910.    137209  \n 2 Latitude                  0        1          26.2        0.719     24.4\n 3 Longitude                 0        1         -80.4        0.616    -85.7\n 4 Month                     0        1           6.71       3.44       1  \n 5 Day                      28        0.999      12.4        7.63       1  \n 6 Year                      0        1        2021.         2.10    2005  \n 7 Value                     0        1           0.112      0.444      0  \n 8 Sample.Depth           1365        0.960       2.83      21.5        0  \n 9 Total.Depth           32972        0.0385      5.17       7.85       0.5\n10 verbatimValue             0        1           0.112      0.444      0  \n11 VerbatimLatitude          0        1          26.2        0.719     24.4\n12 verbatimLongitude         0        1         -80.4        0.616    -85.7\n13 Value_orig                0        1           0.112      0.444      0  \n          p25         p50        p75      p100 hist \n 1 152369     160942      700847     709935    ▇▁▁▁▅\n 2     25.8       26.1        26.7       30.8  ▂▇▂▁▁\n 3    -80.4      -80.1       -80.1      -80.0  ▁▁▁▁▇\n 4      4          7          10         12    ▇▅▅▆▇\n 5      6         11          18         31    ▇▆▅▃▂\n 6   2019       2021        2023       2024    ▁▁▁▅▇\n 7      0.005      0.0097      0.054      7.71 ▇▁▁▁▁\n 8      0.5        0.5         0.787   2494    ▇▁▁▁▁\n 9      0.704      2.82        6.4       52.7  ▇▁▁▁▁\n10      0.005      0.0097      0.054      7.71 ▇▁▁▁▁\n11     25.8       26.1        26.7       30.8  ▂▇▂▁▁\n12    -80.4      -80.1       -80.1      -80.0  ▁▁▁▁▇\n13      0.005      0.0097      0.054      7.71 ▇▁▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "parameter_reports/Nitrogen- Total.html",
    "href": "parameter_reports/Nitrogen- Total.html",
    "title": "Nitrogen- Total",
    "section": "",
    "text": "Nitrogen- Total Report\n\n\nCode\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  glue,\n  here,\n  skimr,\n  ggplot2\n)\n\ndata &lt;- read.csv(here(\"data/df_cleaned.csv\"))\nparameter_name &lt;- params$parameter_name\n\n\n\n\napply param bounds\nbounds &lt;- read.csv(here(\"parameter_bounds.csv\"), stringsAsFactors = FALSE, strip.white = T)\nlower_bound &lt;- bounds$min[bounds$param == parameter_name]\nupper_bound &lt;- bounds$max[bounds$param == parameter_name]\n\nfilter_condition &lt;- (data$Parameter == parameter_name & (data$Value &lt; lower_bound | data$Value &gt; upper_bound))\n\ntryCatch({  # this tryCatch is for when filter_condition is logical(0) i.e. no matches\n  data &lt;- dplyr::filter(\n    data, \n    !filter_condition\n  )\n  print(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n}, error = function(e){\n  print(glue(\"no rows removed\"))\n})\n\n\n0 rows dropped as &lt; 0 or &gt; 6\n\n\napply param bounds\nprint(glue(\"{sum(filter_condition)} rows dropped as &lt; {lower_bound} or &gt; {upper_bound}\"))\n\n\n0 rows dropped as &lt; 0 or &gt; 6\n\n\n\n\nwrite cleaned DataFrame to a file\nwrite.csv(data, here(\"data/df_cleaned_02.csv\"), row.names = FALSE)\n\n\n\n\nload data & skim\nsubset_data &lt;- subset(data, Parameter == parameter_name)\nprint(skimr::skim(subset_data))\n\n\n── Data Summary ────────────────────────\n                           Values     \nName                       subset_data\nNumber of rows             23143      \nNumber of columns          17         \n_______________________               \nColumn type frequency:                \n  character                4          \n  numeric                  13         \n________________________              \nGroup variables            None       \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Source                0             1   3  10     0        4          0\n2 Site                  0             1   1  28     0      656          0\n3 Parameter             0             1  15  15     0        1          0\n4 Units                 0             1   4   6     0        2          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n   skim_variable     n_missing complete_rate       mean         sd       p0\n 1 ...1                      0         1     494765.    111543.    403997  \n 2 Latitude                  0         1         25.6        1.05      24.5\n 3 Longitude                 0         1        -80.9        0.630    -82.6\n 4 Month                     0         1          6.72       3.37       1  \n 5 Day                       0         1         15.6        8.63       1  \n 6 Year                      0         1       2014.         8.88    1995  \n 7 Value                     0         1          0.587      0.631      0  \n 8 Sample.Depth             10         1.00       2.17       4.95       0  \n 9 Total.Depth            8915         0.615      7.56       7.65       0  \n10 verbatimValue             0         1          0.587      0.631      0  \n11 VerbatimLatitude          0         1         25.6        1.05      24.5\n12 verbatimLongitude         0         1        -80.9        0.630    -82.6\n13 Value_orig                0         1          0.587      0.631      0  \n          p25        p50        p75      p100 hist \n 1 411570.    424437     651330.    657440    ▇▁▁▁▃\n 2     24.7       25.1       26.4       28.4  ▇▂▂▂▁\n 3    -81.4      -80.9      -80.3      -80.0  ▁▃▅▅▇\n 4      4          7         10         12    ▇▅▆▆▇\n 5      8         15         23         31    ▇▇▇▆▆\n 6   2007       2016       2023       2023    ▂▂▂▃▇\n 7      0.146      0.241      0.992      5.83 ▇▂▁▁▁\n 8      0.5        0.5        0.5      121.   ▇▁▁▁▁\n 9      2.90       5.25       9.58     121.   ▇▁▁▁▁\n10      0.146      0.241      0.992      5.83 ▇▂▁▁▁\n11     24.7       25.1       26.4       28.4  ▇▂▂▂▁\n12    -81.4      -80.9      -80.3      -80.0  ▁▃▅▅▇\n13      0.146      0.241      0.992      5.83 ▇▂▁▁▁\n\n\n\n\ncreate params$parameter_name histogram\nggplot2::ggplot(subset_data, aes(x=Value)) +\n    geom_histogram(bins=30, fill=\"blue\", color=\"black\") +\n    scale_y_log10() +  # Transform the y-axis to a logarithmic scale\n    labs(title=paste(\"Histogram of Values for\", params$parameter_name),\n         x=\"Value\",\n         y=\"Log Frequency\") +\n    theme_minimal()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "provider_sites_report.html",
    "href": "provider_sites_report.html",
    "title": "Sites Report",
    "section": "",
    "text": "A summary of which sites meet quality assessment checks to be included in the final map.\n\n\n(code) import libraries, functions, & data\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  ggplot2,\n  dplyr\n)\nsource(\"R/getData.R\")\ndata &lt;- getData()\n\n\n\n\nshow unique providers\nunique_sources &lt;- unique(data$Source)\nprint(unique_sources)\n\n\n [1] \"AOML\"                  \"DERM\"                  \"BROWARD\"              \n [4] \"DEP\"                   \"FIU\"                   \"21FLWQA\"              \n [7] \"BBAP\"                  \"Miami Beach\"           \"Miami Beach  Outfalls\"\n[10] \"Miami Beach Re-Sample\" \"BBWW\"                  \"Palm Beach\"           \n\n\n\n\nshow % of clean data per site\n# Count for raw dataframe\nraw_counts &lt;- getRawData() %&gt;%\n  group_by(Source) %&gt;%\n  summarise(Count = n(), .groups = 'drop') %&gt;%\n  mutate(Condition = \"Before Cleaning\")\n\n\nNew names:\n• `` -&gt; `...1`\n\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `Value = as.numeric(Value)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nshow % of clean data per site\n# Count for cleaned dataframe\ncleaned_counts &lt;- getData() %&gt;%\n  group_by(Source) %&gt;%\n  summarise(Count = n(), .groups = 'drop') %&gt;%\n  mutate(Condition = \"After Cleaning\")\n\ncombined_counts &lt;- bind_rows(raw_counts, cleaned_counts)\n\nggplot(combined_counts, aes(x = Source, y = Count, fill = Condition)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Number of Rows Per Source Before and After Cleaning\",\n       x = \"Source\",\n       y = \"Number of Rows\",\n       fill = \"Condition\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability"
  },
  {
    "objectID": "data_details.html",
    "href": "data_details.html",
    "title": "Data Details",
    "section": "",
    "text": "(code) import libraries & functions\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  # If not installed, install the package\n  install.packages(\"librarian\")\n}\n\nlibrarian::shelf(\n  readr,\n  skimr,\n  glue,\n  ggplot2,\n  quarto\n)\nsource(\"R/getData.R\")\n\n\nThere are three relevant types of data file provided:\n\n\n(code) preview the raw data\ninspectData &lt;- function(fpath){\n  print(fpath)\n  df &lt;- readr::read_csv(fpath)\n  print(head(df))\n}\n\ninspectData(\"data/station_sampling_periods_for_all_programs.csv\")\n\n\n[1] \"data/station_sampling_periods_for_all_programs.csv\"\n\n\nRows: 998 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Source, Site, Currently Sampling?, Notes\ndbl (4): Lat, Long, Sample Start Year, Sample End Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 6 × 8\n  Source Site    Lat  Long `Sample Start Year` `Sample End Year`\n  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;               &lt;dbl&gt;             &lt;dbl&gt;\n1 DERM   AC01   25.9 -80.1                2015              2021\n2 DERM   AC03   25.9 -80.2                2015              2021\n3 DERM   AC06   25.9 -80.2                2015              2021\n4 DERM   AR03   25.3 -80.4                2015              2021\n5 DERM   BB02   25.9 -80.1                2015              2021\n6 DERM   BB04   25.9 -80.1                2015              2021\n# ℹ 2 more variables: `Currently Sampling?` &lt;chr&gt;, Notes &lt;chr&gt;\n\n\n(code) preview the raw data\ninspectData(\"data/Unified_WQ_Database(2023 updated).csv\")\n\n\n[1] \"data/Unified_WQ_Database(2023 updated).csv\"\n\n\nNew names:\nRows: 715257 Columns: 13\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(6): Source, Site, Longitude, Parameter, Value, Units dbl (7): ...1, Latitude,\nMonth, Day, Year, Sample Depth, Total Depth\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\n# A tibble: 6 × 13\n   ...1 Source Site  Latitude Longitude  Month   Day  Year Parameter Value Units\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;\n1     1 AOML   1         25.6 -80.12666…     1    29  1998 Chloroph… 1.00… ug/L \n2     2 AOML   2         25.6 -80.105        1    29  1998 Chloroph… 0.55… ug/L \n3     3 AOML   3         25.6 -80.08333…     1    29  1998 Chloroph… 0.69… ug/L \n4     4 AOML   4         25.1 -80.38         1    29  1998 Chloroph… 0.42… ug/L \n5     5 AOML   5         25.1 -80.35333…     1    29  1998 Chloroph… 0.66… ug/L \n6     6 AOML   6         25.1 -80.315        1    29  1998 Chloroph… 0.26… ug/L \n# ℹ 2 more variables: `Sample Depth` &lt;dbl&gt;, `Total Depth` &lt;dbl&gt;\n\n\nHere is a summarizing table of what I see in each file we were provided:\n\n\n\n\n\n\n\n\n\nfilename\ngeospatial info\ndt info\n\n\n\n\n\nMerged_*.csv\ndepth?+source+site\nMM-YYYY\n\n\n\nstation_sampling_periods_for_all_programs.csv\nlat+lon+source+site\n\nstart+end year + still sampling\n\n\nUnified_WQ_Database_*.csv\nlat+lon+source+site\nMM-YYYY\nstart+end + still sampling\n\n\n\nSo… in theory Unified_WQ_Database_*.csv contains everything we could need.\n\nExploratory analyses\nA skim view of the data as it loads in:\n\n\n(code) skim the data\ndata &lt;- readr::read_csv(\"data/Unified_WQ_Database(2023 updated).csv\")\n\nskimr::skim(data)\n\n\n\nData summary\n\n\nName\ndata\n\n\nNumber of rows\n715257\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSource\n94\n1.00\n3\n21\n0\n12\n0\n\n\nSite\n0\n1.00\n1\n28\n0\n2510\n0\n\n\nLongitude\n19248\n0.97\n3\n12\n0\n10580\n0\n\n\nParameter\n0\n1.00\n6\n24\n0\n12\n0\n\n\nValue\n138417\n0.81\n1\n13\n0\n96308\n0\n\n\nUnits\n968\n1.00\n2\n9\n0\n12\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\n…1\n0\n1.00\n357629.00\n206477.06\n1.00\n178815.00\n357629.00\n536443.00\n715257.00\n▇▇▇▇▇\n\n\nLatitude\n19208\n0.97\n25.42\n0.83\n23.67\n24.71\n25.17\n25.90\n30.79\n▇▇▂▁▁\n\n\nMonth\n114\n1.00\n6.56\n3.42\n1.00\n4.00\n7.00\n10.00\n12.00\n▇▅▆▅▇\n\n\nDay\n1614\n1.00\n14.12\n8.23\n1.00\n7.00\n13.00\n20.00\n31.00\n▇▇▆▅▃\n\n\nYear\n114\n1.00\n2012.47\n8.90\n1995.00\n2004.00\n2015.00\n2021.00\n2024.00\n▃▃▃▃▇\n\n\nSample Depth\n22214\n0.97\n3.57\n12.20\n0.00\n0.50\n0.50\n3.50\n2494.00\n▇▁▁▁▁\n\n\nTotal Depth\n343781\n0.52\n9.01\n9.49\n0.00\n3.00\n6.00\n11.18\n120.57\n▇▁▁▁▁\n\n\n\n\n\nThe Value is reading in as “Character” when it should be “Numeric”. We can convert it and view the rows that are being lost because they read as non-numeric:\n\n\n(code) view bad rows\ndata &lt;- getData()  # the getData in getData.R reads and converts the Value col \n\nna_rows &lt;- is.na(data$Value) & !is.na(data$Value_orig)\nna_introduced_rows &lt;- data[na_rows, ]\n\nprint(na_introduced_rows)\n\n\n# A tibble: 0 × 17\n# ℹ 17 variables: ...1 &lt;dbl&gt;, Source &lt;chr&gt;, Site &lt;chr&gt;, Latitude &lt;dbl&gt;,\n#   Longitude &lt;dbl&gt;, Month &lt;dbl&gt;, Day &lt;dbl&gt;, Year &lt;dbl&gt;, Parameter &lt;chr&gt;,\n#   Value &lt;dbl&gt;, Units &lt;chr&gt;, Sample.Depth &lt;dbl&gt;, Total.Depth &lt;dbl&gt;,\n#   verbatimValue &lt;dbl&gt;, VerbatimLatitude &lt;dbl&gt;, verbatimLongitude &lt;dbl&gt;,\n#   Value_orig &lt;dbl&gt;\n\n\nThe unique problem values in the “Values” column:\n\n\n(code) view bad Value values\nprint(unique(na_introduced_rows$Value_orig))\n\n\nnumeric(0)"
  }
]